[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "trading-chart"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "trading-chart-core",
]


[tool.uv.workspace]
members = [
    "src/core",
    "src/libs/aggregation",
    "src/libs/auth",
    "src/libs/data_quality",
    "src/libs/indicators",
    "src/libs/resilience",
    "src/libs/streaming",
    "src/integrations",
    "src/apps",
]

[tool.uv.sources]
trading-chart-core = { workspace = true }

[tool.ruff]
line-length = 120
target-version = "py311"
exclude = [
    "**/tests",
    "old-project",
]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disable_error_code = ["annotation-unchecked"]
exclude = [
    "src/.*/tests",
    "tests/e2e",
    "old-project",
]

[tool.pytest.ini_options]
minversion = "6.0"
testpaths = [
    "src/*/tests/unit",
    "src/*/tests/integration", 
    "src/*/tests/contract",
    "src/*/tests/benchmark",
    "tests/e2e"
]
timeout = 60  # Default timeout: 60 seconds for non-unit tests
addopts = [
    "--strict-markers",
    "--strict-config",
    "--verbose",
    "--timeout=60",
    "--timeout-method=thread",
]
filterwarnings = [
    # Ignore fixture marks warning from pytest itself
    "ignore:Marks applied to fixtures have no effect:pytest.PytestRemovedIn9Warning",
    # Ignore pytest-benchmark asyncio coroutine warnings
    "ignore:coroutine.*was never awaited:RuntimeWarning"
]
markers = [
    # Test levels
    "unit: Unit tests - fast, isolated, no external dependencies",
    "integration: Integration tests - test component interactions",
    "e2e: End-to-end tests - full system tests",
    "contract: Contract tests - interface compliance tests",
    "benchmark: Benchmark tests - performance measurements",
    "config: Tests related to configuration",

    # Special attributes
    "slow: Slow running tests (>1s)",
    "external: Tests requiring external services",
    "asyncio: Asynchronous tests",
    "concurrency: Tests involving concurrency",
    "timeout: Tests with timeout restrictions",
    
    # Logging specific
    "enable_loguru_file_io: Enable actual loguru file I/O for testing file logging functionality",

]

# Unit test timeout configuration
# pytest-timeout is configured via pytest hooks in conftest.py

[tool.uv]
dev-dependencies = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "ruff>=0.1.0",
    "mypy>=1.0",
    "poethepoet>=0.27.0",
    "pytest-asyncio>=0.23.0",
    "pytest-benchmark>=5.1.0",
    "pytest-timeout>=2.1.0",
    "pytest-repeat>=0.9.4", # Remove
    "time-machine>=2.13.0",
    "import-linter>=2.0",
    # Security scanning tools
    "safety>=3.0",
    "bandit>=1.7.0",
    "pip-audit>=2.6.0",
    "semgrep>=1.45.0",
    "psutil>=7.0.0",
]

[tool.poe.tasks]
lint = "ruff check ."
format = "ruff format ."
test = "pytest"
check-format = "ruff format ."
check-types = "mypy ."
check-deps = { shell = "cd src/core && lint-imports" }
check = ["check-format", "lint", "check-types", "check-deps"]

# Test classification tasks
test-unit = "pytest -m unit"
test-integration = "pytest -m integration"
test-contract = "pytest -m contract"
test-benchmark = "pytest -m benchmark"
test-fast = "pytest -m 'not slow'"
test-slow = "pytest -m slow"
test-all = "pytest"

check-security = ["security-deps", "security-code"]
security-deps = "safety check --json --ignore 67599"
security-code = "bandit -r src/ -f json"
security-audit = "pip-audit --format=json"
security-semgrep = "semgrep --config=auto --json src/"
security-full = ["security-deps", "security-code", "security-audit", "security-semgrep"]

validate = ["check", "test"]
